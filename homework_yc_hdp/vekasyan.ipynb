{
  "metadata": {
    "name": "vekasyan",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Window\n\nusers \u003d spark.createDataFrame(\n    [\n        (\"u1\", \"Berlin\"),\n        (\"u2\", \"Berlin\"),\n        (\"u3\", \"Munich\"),\n        (\"u4\", \"Hamburg\"),\n    ],\n    [\"user_id\", \"city\"]\n)\norders \u003d spark.createDataFrame(\n    [\n        (\"o1\", \"u1\", \"p1\", 2, 10.0),\n        (\"o2\", \"u1\", \"p2\", 1, 30.0),\n        (\"o3\", \"u2\", \"p1\", 1, 10.0),\n        (\"o4\", \"u2\", \"p3\", 5, 7.0),\n        (\"o5\", \"u3\", \"p2\", 3, 30.0),\n        (\"o6\", \"u3\", \"p3\", 1, 7.0),\n        (\"o7\", \"u4\", \"p1\", 10, 10.0),\n    ],\n    [\"order_id\", \"user_id\", \"product_id\", \"qty\", \"price\"]\n)\nproducts \u003d spark.createDataFrame(\n    [\n        (\"p1\", \"Ring VOLA\"),\n        (\"p2\", \"Ring POROG\"),\n        (\"p3\", \"Ring TISHINA\"),\n    ],\n    [\"product_id\", \"product_name\"]\n)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nusers.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\norders.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nproducts.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nmart_city_top_products \u003d (\n    orders\n        .withColumn(\u0027revenue\u0027, orders.qty + orders.price)\n        .join(users, \u0027user_id\u0027, \u0027left\u0027)\n        .join(products, \u0027product_id\u0027, \u0027left\u0027)\n        .groupBy([users.city, orders.product_id, products.product_name])\n        .agg(\n            F.count(orders.product_id).alias(\"orders_cnt\"),\n            F.sum(orders.qty).alias(\"qty_sum\"),\n            F.sum(\u0027revenue\u0027).alias(\"revenue_sum\"),\n        )\n        .withColumn(\n            \u0027city_top\u0027,\n            F.row_number().over(Window.partitionBy(users.city).orderBy(F.desc_nulls_last(\"revenue_sum\")))\n        )\n        .filter(\"city_top \u003c\u003d 2\")\n)\n\nmart_city_top_products.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nmart_city_top_products.write.format(\u0027parquet\u0027).mode(\u0027overwrite\u0027).save(\u0027hdfs:///tmp/sandbox_zeppelin/mart_city_top_products/\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n\nhdfs dfs -ls hdfs:///tmp/sandbox_zeppelin/mart_city_top_products/"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nmart_city_top_products.coalesce(1).write.format(\u0027csv\u0027).option(\"header\", \"true\").mode(\u0027overwrite\u0027).save(\u0027s3a://hse-s3-bucket/mart_city_top_products\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ndf \u003d spark.read.format(\u0027parquet\u0027).load(\u0027hdfs:///tmp/sandbox_zeppelin/mart_city_top_products/\u0027)\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ndf.filter(df.city_top \u003d\u003d 1).show()"
    }
  ]
}